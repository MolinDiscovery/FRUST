{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a00cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import submitit\n",
    "import inspect\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from frust.stepper import Stepper\n",
    "import frust.vis as vis\n",
    "from pathlib import Path\n",
    "from tooltoad.chemutils import xyz2mol\n",
    "\n",
    "from rdkit import Chem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75923c5",
   "metadata": {},
   "source": [
    "# Live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfd7679e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted Slurm job IDs: ['55096764', '55096765', '55096766', '55096767', '55096768', '55096769', '55096770', '55096771', '55096772', '55096773', '55096774', '55096775', '55096776', '55096777', '55096778', '55096779', '55096780', '55096781', '55096782', '55096783', '55096784', '55096785', '55096786', '55096787', '55096788', '55096789', '55096790', '55096791', '55096792', '55096793', '55096794', '55096795', '55096796', '55096797', '55096798', '55096799', '55096800', '55096801', '55096802', '55096803', '55096804', '55096805']\n"
     ]
    }
   ],
   "source": [
    "# scripts/submit_multistage_ts_rpos.py\n",
    "import os\n",
    "import re\n",
    "import importlib\n",
    "import inspect\n",
    "import pandas as pd\n",
    "import submitit\n",
    "\n",
    "# ─── CONFIG ─────────────────────────────────────────────────────────────\n",
    "MODULE_PATH   = \"frust.pipelines.run_ts_per_rpos\"  # your run_* module\n",
    "CSV_PATH      = \"../datasets/dft_finalists.csv\"\n",
    "TS_XYZ        = \"../structures/ts4_TMP.xyz\"\n",
    "\n",
    "ROOT_SAVE_DIR = \"dft_finalists_ts4\"\n",
    "WORK_DIR      = None\n",
    "LOG_DIR       = f\"logs/{ROOT_SAVE_DIR}\"\n",
    "\n",
    "PARTITION     = \"kemi1\"\n",
    "USE_SLURM     = True\n",
    "DEBUG         = False\n",
    "PRODUCTION    = True\n",
    "N_CONFS       = None if PRODUCTION else 1\n",
    "\n",
    "RES = {\n",
    "    \"run_init\":   dict(cpus=16, mem=20, time=7200),\n",
    "    \"run_hess\":   dict(cpus=8, mem=64, time=7200),\n",
    "    \"run_OptTS\":  dict(cpus=16, mem=20, time=7200),\n",
    "    \"run_freq\":   dict(cpus=8, mem=64, time=7200),\n",
    "    \"run_solv\":   dict(cpus=16,  mem=20, time=3600),\n",
    "    \"run_cleanup\": dict(cpus=2, mem=2,  time=60),\n",
    "}\n",
    "\n",
    "\n",
    "# ─── HELPERS ────────────────────────────────────────────────────────────\n",
    "def _sanitize(s: str) -> str:\n",
    "    return re.sub(r\"[^A-Za-z0-9_.-]+\", \"_\", s)\n",
    "\n",
    "def _tag_from_ts_struct(ts_struct: dict) -> str:\n",
    "    return _sanitize(list(ts_struct.keys())[0])\n",
    "\n",
    "def _stage_res(fn_name: str):\n",
    "    r = RES.get(fn_name, dict(cpus=4, mem=20, time=720))\n",
    "    return r[\"cpus\"], r[\"mem\"], r[\"time\"]\n",
    "\n",
    "def _clear_sticky(executor):\n",
    "    executor.update_parameters(slurm_additional_parameters={})\n",
    "\n",
    "def _submit(executor, fn, kwargs, fn_name, tag, dep_job):\n",
    "    _clear_sticky(executor)\n",
    "    cpus, mem, tmo = _stage_res(fn_name)\n",
    "    extra = {\"dependency\": f\"afterok:{dep_job.job_id}\",\n",
    "             \"exclude\": \"node236,node237,node238,node239\"} if (USE_SLURM and dep_job) else {}\n",
    "    executor.update_parameters(\n",
    "        slurm_job_name=f\"{tag}_{fn_name}\" if USE_SLURM else None,\n",
    "        slurm_partition=PARTITION if USE_SLURM else None,\n",
    "        cpus_per_task=cpus,\n",
    "        mem_gb=mem,\n",
    "        timeout_min=tmo,\n",
    "        slurm_additional_parameters=extra,\n",
    "    )\n",
    "    return executor.submit(fn, **kwargs)\n",
    "\n",
    "def _next_parquet(current: str, fn_name: str) -> str:\n",
    "    \"\"\"Return the parquet filename produced by fn_name, given current input.\"\"\"\n",
    "    stem = current.rsplit(\".\", 1)[0]\n",
    "    if fn_name == \"run_hess\":\n",
    "        return f\"{stem}.hess.parquet\"\n",
    "    if fn_name == \"run_OptTS\":\n",
    "        return f\"{stem}.optts.parquet\"\n",
    "    if fn_name == \"run_freq\":\n",
    "        return f\"{stem}.freq.parquet\"\n",
    "    if fn_name == \"run_solv\":\n",
    "        return f\"{stem}.solv.parquet\"\n",
    "    return current  # run_init / run_cleanup don’t change the chain\n",
    "\n",
    "# ─── LOAD PIPE & DISCOVER STAGES (order-of-definition) ──────────────────\n",
    "mod = importlib.import_module(MODULE_PATH)\n",
    "runs = [obj for name, obj in mod.__dict__.items()\n",
    "        if name.startswith(\"run_\") and callable(obj)]\n",
    "\n",
    "# ─── INPUT PREP ─────────────────────────────────────────────────────────\n",
    "from frust.utils.mols import create_ts_per_rpos\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "smi_list = list(dict.fromkeys(df[\"smiles\"]))\n",
    "job_inputs = create_ts_per_rpos(smi_list, TS_XYZ)\n",
    "\n",
    "os.makedirs(ROOT_SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "# ─── EXECUTOR ───────────────────────────────────────────────────────────\n",
    "executor = submitit.AutoExecutor(LOG_DIR) if USE_SLURM else submitit.LocalExecutor(LOG_DIR)\n",
    "executor.update_parameters(\n",
    "    slurm_partition=PARTITION if USE_SLURM else None,\n",
    "    cpus_per_task=4, mem_gb=20, timeout_min=720\n",
    ")\n",
    "\n",
    "# ─── SUBMIT CHAINS ──────────────────────────────────────────────────────\n",
    "all_jobs = []\n",
    "for ts_struct in job_inputs:\n",
    "    tag = _tag_from_ts_struct(ts_struct)\n",
    "    save_dir = os.path.join(ROOT_SAVE_DIR, tag)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    last_job = None\n",
    "    current_parquet = \"init.parquet\"  # input to run_hess; produced by run_init\n",
    "\n",
    "    for fn in runs:\n",
    "        fn_name = fn.__name__\n",
    "        sig = inspect.signature(fn)\n",
    "\n",
    "        # Build kwargs respecting each function's signature\n",
    "        kwargs = {\"save_dir\": save_dir, \"work_dir\": WORK_DIR, \"debug\": DEBUG}\n",
    "\n",
    "        if fn_name == \"run_init\":\n",
    "            kwargs.update({\n",
    "                \"ts_struct\": ts_struct,\n",
    "                \"n_confs\": N_CONFS,\n",
    "                \"n_cores\": _stage_res(fn_name)[0],\n",
    "                \"mem_gb\":  _stage_res(fn_name)[1],\n",
    "            })\n",
    "        elif fn_name == \"run_cleanup\":\n",
    "            kwargs = {\"save_dir\": save_dir}\n",
    "        else:\n",
    "            # Input to this stage is the parquet produced by the previous stage\n",
    "            kwargs.update({\n",
    "                \"parquet_path\": current_parquet,\n",
    "                \"n_cores\": _stage_res(fn_name)[0],\n",
    "                \"mem_gb\":  _stage_res(fn_name)[1],\n",
    "            })\n",
    "\n",
    "        # Trim kwargs to the function signature\n",
    "        kwargs = {k: v for k, v in kwargs.items() if k in sig.parameters}\n",
    "\n",
    "        # Submit with dependency on previous stage (if any)\n",
    "        job = _submit(executor, fn, kwargs, fn_name, tag, last_job)\n",
    "        all_jobs.append(job)\n",
    "        last_job = job\n",
    "\n",
    "        # After submitting, update current_parquet to the file this stage will produce\n",
    "        if fn_name not in (\"run_init\", \"run_cleanup\"):\n",
    "            current_parquet = _next_parquet(current_parquet, fn_name)\n",
    "\n",
    "    _clear_sticky(executor)\n",
    "\n",
    "print(\"Submitted Slurm job IDs:\", [j.job_id for j in all_jobs])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UMA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
